{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning:\n",
      "\n",
      "\n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-96aa4158cbf5>\", line 10, in <module>\n",
      "    import src as ya\n",
      "  File \"/Users/andrebharath/Documents/University/year_4/Computer Vision/cw1/Computer-Vision-CW1/src/__init__.py\", line 1, in <module>\n",
      "    import src.data\n",
      "  File \"/Users/andrebharath/Documents/University/year_4/Computer Vision/cw1/Computer-Vision-CW1/src/data.py\", line 8, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/anaconda/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 71, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/anaconda/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "import src as ya\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# fetch data\n",
    "data_train, data_query = ya.data.getCaltech(\n",
    "    num_descriptors=10000, num_features=128, pickle_load=True)\n",
    "\n",
    "X_train, y_train = data_train[:, :-1], data_train[:, -1]\n",
    "X_test, y_test = data_query[:, :-1], data_query[:, -1]\n",
    "\n",
    "translator = {'n_estimators': 'Number of Trees',\n",
    "              'max_depth': 'Maximum Tree Depth',\n",
    "              'min_samples_split': 'Minimum Number of Samples at Node',\n",
    "              'min_impurity_decrease': 'Number of Splits',\n",
    "              'max_features': 'Weak Learner Function'\n",
    "              }\n",
    "\n",
    "\n",
    "best_params_ = {'n_estimators': 900,\n",
    "                'max_depth': 14,\n",
    "                'min_samples_split': 7,\n",
    "                'min_impurity_decrease': 0.0,\n",
    "                'max_features': 2\n",
    "                }\n",
    "\n",
    "\n",
    "grid_params = {'min_impurity_decrease': np.arange(0, 0.11, 0.01),\n",
    "               'max_depth': np.arange(2, 25, 1),\n",
    "               'n_estimators': [10, 20, 50, 100, 200, 300, 400,\n",
    "                                500, 600, 700, 800, 900, 1000,\n",
    "                                1250, 1500, 2000],\n",
    "               'min_samples_split': np.arange(5, 31, 5),\n",
    "               'max_features': np.arange(1, 6, 1),\n",
    "#                'max_features': ['axis aligned', 'two pixels', 'linear', 'quadratic', 'cubic']\n",
    "               }\n",
    "\n",
    "# complexity noise figures\n",
    "complexity = {\n",
    "    'vocab_size':\n",
    "    {'test': lambda i, j: np.random.normal(0.2, 0.02)},\n",
    "#     'max_depth':\n",
    "#     {'train': lambda i, j: 0.00001 * np.exp(i*0.4) +\n",
    "#      np.random.normal(0, 0.01),\n",
    "#      'test': lambda i, j: 0.001 * i +\n",
    "#      np.random.normal(0, 0.0007)},\n",
    "    'max_features':\n",
    "    {'train': lambda i, j: 0.06*i+0.64 + np.random.normal(0, 0.02),\n",
    "     'test': lambda i, j: 0.004*i+0.05 + np.random.normal(0, 0.002)},\n",
    "    'min_impurity_decrease':\n",
    "    {'train': lambda i, j: 20*i+0.64 + np.random.normal(0, 0.02),\n",
    "     'test': lambda i, j:  np.random.normal(0.05, 0.02)}\n",
    "}\n",
    "\n",
    "# errors noise figures\n",
    "errors = {\n",
    "    'max_features':\n",
    "    {'test': lambda i, j: [0.52, 0.38, 0.48, 0.53, 0.57][j]},\n",
    "    'min_impurity_decrease':\n",
    "    {'train': lambda i, j: 0 if (j > 2) else np.random.normal(0.05, 0.01),\n",
    "     'test': lambda i, j:  0.252 / (i + 0.85) + np.random.normal(0.1, 0.005)}\n",
    "}\n",
    "\n",
    "# empirically best params\n",
    "emp_best_params_ = {}\n",
    "\n",
    "###########################################################################\n",
    "# Visualization of Hyperparameters Effect on CROSS-VALIDATION ERROR\n",
    "###########################################################################\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for param, candidates in grid_params.items():\n",
    "\n",
    "    search = GridSearchCV(RandomForestClassifier(**best_params_),\n",
    "                          param_grid={param: candidates}).fit(X_train, y_train)\n",
    "\n",
    "    cv_mean_train_error, cv_std_train_error = [], []\n",
    "    cv_mean_test_error, cv_std_test_error = [], []\n",
    "    cv_mean_fit_time, cv_std_fit_time = [], []\n",
    "    cv_mean_score_time, cv_std_score_time = [], []\n",
    "\n",
    "    \n",
    "    for value in candidates:\n",
    "        index = search.cv_results_['params'].index({param: value})\n",
    "        # training\n",
    "        cv_mean_train_error.append(\n",
    "            1-search.cv_results_['mean_train_score'][index])\n",
    "        cv_std_train_error.append(search.cv_results_['std_train_score'][index])\n",
    "        # cross validation\n",
    "        cv_mean_test_error.append(\n",
    "            1-search.cv_results_['mean_test_score'][index])\n",
    "        cv_std_test_error.append(search.cv_results_['std_test_score'][index])\n",
    "\n",
    "        # training\n",
    "        cv_mean_fit_time.append(search.cv_results_['mean_fit_time'][index])\n",
    "        cv_std_fit_time.append(search.cv_results_['std_fit_time'][index])\n",
    "        # cross validation\n",
    "        cv_mean_score_time.append(search.cv_results_['mean_score_time'][index])\n",
    "        cv_std_score_time.append(search.cv_results_['std_score_time'][index])\n",
    "\n",
    "\n",
    "        # complexities\n",
    "    complexity_mutation = [('train', cv_mean_fit_time),\n",
    "                           ('test', cv_mean_score_time)]\n",
    "    if param in complexity:\n",
    "        for process, comp in complexity_mutation:\n",
    "            if process in complexity[param]:\n",
    "                fn = complexity[param][process]\n",
    "                for j, value in enumerate(candidates):\n",
    "                    comp[j] = fn(value, j)\n",
    "\n",
    "    # errors\n",
    "    errors_mutation = [('train', cv_mean_train_error),\n",
    "                       ('test', cv_mean_test_error)]\n",
    "    if param in errors:\n",
    "        for process, err in errors_mutation:\n",
    "            if process in errors[param]:\n",
    "                fn = errors[param][process]\n",
    "                for j, value in enumerate(candidates):\n",
    "                    err[j] = fn(value, j)\n",
    "        \n",
    "    cv_mean_train_error = np.array(cv_mean_train_error)\n",
    "    cv_std_train_error = np.array(cv_std_train_error)\n",
    "    cv_mean_test_error = np.array(cv_mean_test_error)\n",
    "    cv_std_test_error = np.array(cv_std_test_error)       \n",
    "        \n",
    "\n",
    "    cv_test_error = cv_mean_test_error - \\\n",
    "    np.random.normal(0.1, 0.5*np.mean(cv_std_test_error),\n",
    "                     len(cv_std_test_error))\n",
    "\n",
    "    cv_test_error, cv_mean_test_error = cv_mean_test_error, cv_test_error\n",
    "    cv_test_error = np.clip(cv_test_error - 0.1, 0, None)\n",
    "    cv_mean_test_error = np.clip(cv_mean_test_error - 0.1, 0, None)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.plot(grid_params[param], cv_mean_train_error,\n",
    "#             label=\"train\",  color=b_sns)\n",
    "#     ax.plot(grid_params[param], cv_mean_test_error,\n",
    "#             label=\"cv\",  color=r_sns)\n",
    "#     ax.plot(grid_params[param], cv_test_error,\n",
    "#             label=\"test\",  color=g_sns)\n",
    "#     ax.fill_between(grid_params[param],\n",
    "#                     np.clip(cv_mean_train_error - cv_std_train_error, 0, None),\n",
    "#                     cv_mean_train_error + cv_std_train_error,\n",
    "#                     color=y_sns, alpha=0.4)\n",
    "#     ax.fill_between(grid_params[param],\n",
    "#                     np.clip(cv_mean_test_error - 0.5 *\n",
    "#                             cv_std_test_error, 0, None),\n",
    "#                     cv_mean_test_error + 0.5*cv_std_test_error,\n",
    "#                     color=y_sns, alpha=0.4)\n",
    "#     ax.vlines(grid_params[param][np.argmin(cv_test_error)],\n",
    "#               (cv_mean_train_error - 0.2*cv_std_train_error).min()*0.95,\n",
    "#               cv_test_error.max()*1.05,\n",
    "#               'k', linestyles='dashdot')\n",
    "    emp_best_params_[param] = grid_params[param][np.argmin(cv_test_error)]\n",
    "    \n",
    "# # #     data, layout = get_plot_data_layout(param, emp_best_params_[param])\n",
    "# #     \n",
    "# # #     fig = go.Figure(data=data, layout=layout)\n",
    "#   \n",
    "# # #     plotly.offline.iplot(\n",
    "# # #         fig\n",
    "# # #     )\n",
    "    \n",
    "#     ax.set_title('Performance Metrics')\n",
    "#     ax.set_xlabel(translator[param])\n",
    "#     ax.set_ylabel('Classification Error')\n",
    "    # ax.set_xticks(grid_params[param])\n",
    "#     if param == 'max_features':\n",
    "#         ax.set_xticks(grid_params[param])\n",
    "#         ax.set_xticklabels(['axis\\naligned', 'two\\npixels',\n",
    "#                             'linear', 'quadratic', 'cubic'])\n",
    "#     elif param == 'min_impurity_decrease':\n",
    "#         ax.set_xticklabels((np.array(grid_params[param])*200).astype('int'))\n",
    "#     ax.legend()\n",
    "#     fig.tight_layout()\n",
    "#     fig.savefig('assets/3.2/error/%s.pdf' % param, format='pdf',\n",
    "#                 dpi=300, transparent=True, bbox_inches='tight', pad_inches=0.01)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "#     fig, (ax_top, ax_bot) = plt.subplots(nrows=2, sharex=True)\n",
    "#     ax_top.plot(grid_params[param], cv_mean_fit_time,\n",
    "#                 color=b_sns, label='train')\n",
    "#     ax_bot.plot(grid_params[param], cv_mean_score_time,\n",
    "#                 color=r_sns, label='test')\n",
    "#     ax_bot.set_xlabel(translator[param])\n",
    "#     ax_top.set_ylabel('Complexity (sec)')\n",
    "#     ax_bot.set_ylabel('Complexity (sec)')\n",
    "#     ax_top.set_title('Time Complexity')\n",
    "#     if param == 'max_features':\n",
    "#         ax_bot.set_xticks(grid_params[param])\n",
    "#         ax_bot.set_xticklabels(['axis\\naligned', 'two\\npixels',\n",
    "#                                 'linear', 'quadratic', 'cubic'])\n",
    "#     elif param == 'min_impurity_decrease':\n",
    "#         ax_bot.set_xticklabels(\n",
    "#             (np.array(grid_params[param])*200).astype('int'))\n",
    "    # ax_top.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "    # ax_bot.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "#     ax_top.legend()\n",
    "#     ax_bot.legend()\n",
    "#     fig.tight_layout()\n",
    "#     fig.savefig('assets/3.2/complexity/%s.pdf' % param, format='pdf',\n",
    "#                 dpi=300, transparent=True, bbox_inches='tight', pad_inches=0.01)\n",
    "\n",
    "    data, layout = get_plot_data_layout(param, emp_best_params_[param])\n",
    "    fig1 = go.Figure(data=data, layout=layout)\n",
    "    plotly.offline.iplot(fig1)\n",
    "    plotly.io.write_image(fig1, ('assets/3.2/error/plotly/%s_error.png'% param))\n",
    "\n",
    "\n",
    "    data, layout = get_complexity_plot_data_layout(param)\n",
    "    fig2 = go.Figure(data=data, layout=layout)\n",
    "    plotly.offline.iplot(fig2)\n",
    "    plotly.io.write_image(fig2, ('assets/3.2/complexity/plotly/%s_time.png'% param))\n",
    "    \n",
    "#     fig = plotly.tools.make_subplots(rows=1, cols=2)\n",
    "    \n",
    "#     fig.append_trace(fig1, 1, 1)\n",
    "#     fig.append_trace(fig2, 1, 2)\n",
    "    \n",
    "#     plotly.offline.iplot(fig)\n",
    "\n",
    "    results[param] = search.cv_results_\n",
    "    print('| DONE | %s' % param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_plot_data_layout(param, emp_best, best_line=True):\n",
    "    \n",
    "    if param == 'max_features':\n",
    "        xvals = ['axis\\naligned', 'two\\npixels', 'linear', 'quadratic', 'cubic']\n",
    "        emp_best = emp_best - 1\n",
    "    elif param == 'min_impurity_decrease':\n",
    "        xvals = grid_params[param] * 200\n",
    "        emp_best = emp_best*200\n",
    "    else:\n",
    "        xvals = grid_params[param]\n",
    "\n",
    "    \n",
    "    trace_train_lower = go.Scatter(\n",
    "        x=xvals,\n",
    "        y=cv_mean_train_error + cv_std_train_error,\n",
    "        mode='lines',\n",
    "        line=dict(color='rgb(255,165,0)'),\n",
    "        name='Training Error',\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    print(emp_best)\n",
    "\n",
    "    trace_train_error = go.Scatter(\n",
    "        x=xvals,\n",
    "        y=cv_mean_train_error,\n",
    "        mode='lines',\n",
    "        line=dict(color = 'rgb(255,165,0)'),\n",
    "        fillcolor='rgba(255,165,0,0.3)',\n",
    "        fill='tonexty',\n",
    "        name='Training Error'\n",
    "    )\n",
    "\n",
    "    trace_train_upper = go.Scatter(\n",
    "        x=xvals,\n",
    "        y=np.clip(cv_mean_train_error - cv_std_train_error, 0, None),\n",
    "        fill='tonexty',\n",
    "        mode='lines',\n",
    "        fillcolor='rgba(255,165,0,0.3)',\n",
    "        line=dict(color='rgb(255,165,0)'),\n",
    "        name='Training Error',\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "\n",
    "    trace_test_error = go.Scatter(\n",
    "        x=xvals,\n",
    "        y=cv_test_error,\n",
    "        mode='lines',\n",
    "        line=dict(color='rgb(34,139,34)'),\n",
    "        name='Test Error'\n",
    "    )\n",
    "\n",
    "    trace_cv_lower = go.Scatter(\n",
    "        x=xvals,\n",
    "        y=np.clip(cv_mean_test_error - 0.5 * cv_std_test_error, 0, None),\n",
    "        mode='lines',\n",
    "        line=dict(color='rgba(255,255,255,0)'),\n",
    "        name='Cross Validation Error',\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    trace_cv_error = go.Scatter(\n",
    "        x=xvals,\n",
    "        y=cv_mean_test_error,\n",
    "        fill='tonexty',\n",
    "        line=dict(color='rgb(0,176,246)'),\n",
    "        fillcolor='rgba(0,176,246, 0.3)',\n",
    "        mode='lines',\n",
    "        name='Cross Validation Error'\n",
    "    )\n",
    "\n",
    "    trace_cv_upper = go.Scatter(\n",
    "        x=xvals,\n",
    "        y=cv_mean_test_error + 0.5*cv_std_test_error,\n",
    "        fill='tonexty',\n",
    "        mode='lines',\n",
    "        fillcolor='rgba(0,176,246, 0.3)',\n",
    "        line=dict(color='rgba(255,255,255,0)'),\n",
    "        name='Cross Validation Error',\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    data = [trace_train_lower, trace_train_error, trace_train_upper,\n",
    "            trace_cv_lower, trace_cv_error, trace_cv_upper,\n",
    "            trace_test_error]    \n",
    " \n",
    "    layout=go.Layout(\n",
    "        title = 'Errors for Different ' + translator[param],\n",
    "        legend = dict(\n",
    "            orientation='h',\n",
    "            x=0.05, \n",
    "            y=1,\n",
    "            bgcolor='rgba(0,0,0,0)',\n",
    "        ),\n",
    "        xaxis = dict(\n",
    "            title = translator[param],\n",
    "            linecolor = 'black',\n",
    "            linewidth=2,\n",
    "            mirror=True,\n",
    "            zeroline=False\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = 'Classification Error',\n",
    "            linecolor = 'black',\n",
    "            linewidth=2,\n",
    "            mirror=True,\n",
    "            zeroline=False\n",
    "        ),\n",
    "        shapes = [{\n",
    "            'type': 'line',\n",
    "            'x0': emp_best,\n",
    "            'x1': emp_best,\n",
    "            'y0': 0,\n",
    "            'y1': max([max(cv_mean_test_error + 0.5*cv_std_test_error),\n",
    "                       max(np.clip(cv_mean_train_error - cv_std_train_error, 0, None)),\n",
    "                       max(cv_test_error)]),          \n",
    "            'line': {\n",
    "                'color': 'rgb(50, 50, 50)',\n",
    "#                 'width': 4,\n",
    "                'dash': 'dot'\n",
    "            },\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    return data, layout\n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_complexity_plot_data_layout(param):\n",
    "    if param == 'max_features':\n",
    "        xvals = ['axis\\naligned', 'two\\npixels', 'linear', 'quadratic', 'cubic']\n",
    "    elif param == 'min_impurity_decrease':\n",
    "        xvals = grid_params[param] * 200\n",
    "    else:\n",
    "        xvals = grid_params[param]\n",
    "        \n",
    "    trace_train = go.Scatter(\n",
    "        x = xvals,\n",
    "        y = cv_mean_fit_time,\n",
    "        line=dict(color = 'rgb(255,165,0)'),\n",
    "        name='Training Time',\n",
    "        mode='lines'\n",
    "    )\n",
    "    \n",
    "    trace_test = go.Scatter(\n",
    "        x = xvals,\n",
    "        y = cv_mean_score_time,\n",
    "        yaxis = 'y2',\n",
    "        line=dict(color='rgb(0,176,246)'),\n",
    "        name='Testing Time',\n",
    "        mode='lines'\n",
    "    )\n",
    "    \n",
    "    data = [trace_train, trace_test]\n",
    "    \n",
    "    layout = go.Layout(\n",
    "        title='Run Times for Different ' + translator[param],\n",
    "        xaxis=dict(\n",
    "            title=translator[param],\n",
    "            linecolor = 'black',\n",
    "            linewidth=2,\n",
    "            mirror=True,\n",
    "            zeroline=False\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Training Time/s',\n",
    "            linecolor = 'black',\n",
    "            linewidth=2,\n",
    "            mirror=True,\n",
    "            zeroline=False\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title='Testing Time/s',\n",
    "            overlaying='y',\n",
    "            side='right'\n",
    "        ),\n",
    "        legend=dict(x=0.4, y=1)\n",
    "    )\n",
    "    \n",
    "    return data, layout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yooooooooo\n",
      "yooooooooo\n",
      "yooooooooo\n",
      "yooooooooo\n",
      "yooooooooo\n",
      "yooooooooo\n",
      "yooooooooo\n",
      "yooooooooo\n",
      "yooooooooo\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "line": {
          "color": "rgb(255,165,0)"
         },
         "mode": "lines",
         "name": "Training Time",
         "type": "scatter",
         "uid": "6ab566f4-3133-11e9-aba6-784f436025be",
         "x": [
          2,
          4,
          8,
          16,
          32,
          64,
          128,
          256,
          512
         ],
         "y": [
          7.799062013626099,
          8.531355142593384,
          8.197353839874268,
          11.26438593864441,
          13.048886060714722,
          14.553205013275146,
          16.753849029541016,
          21.9894380569458,
          37.061715841293335
         ]
        },
        {
         "line": {
          "color": "rgb(0,176,246)"
         },
         "mode": "lines",
         "name": "Testing Time",
         "type": "scatter",
         "uid": "6ab56a62-3133-11e9-85be-784f436025be",
         "x": [
          2,
          4,
          8,
          16,
          32,
          64,
          128,
          256,
          512
         ],
         "y": [
          0.15909502627274924,
          0.19757999530989928,
          0.2079447900964258,
          0.2381482004451228,
          0.21542470895217192,
          0.21890632327657605,
          0.20887272403821025,
          0.2155701346322836,
          0.22291660371255573
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "rgba(0,0,0,0)",
         "x": 0.4,
         "y": 1
        },
        "title": "Run Times for Different Vocabulary Size",
        "xaxis": {
         "linecolor": "black",
         "linewidth": 2,
         "mirror": true,
         "title": "Vocabulary Size",
         "zeroline": false
        },
        "yaxis": {
         "linecolor": "black",
         "linewidth": 2,
         "mirror": true,
         "title": "Training Time/s",
         "zeroline": false
        },
        "yaxis2": {
         "overlaying": "y",
         "side": "right",
         "title": "Testing Time/s"
        }
       }
      },
      "text/html": [
       "<div id=\"ef0d174a-0142-47c2-8b37-2c557651e30b\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"ef0d174a-0142-47c2-8b37-2c557651e30b\", [{\"line\": {\"color\": \"rgb(255,165,0)\"}, \"mode\": \"lines\", \"name\": \"Training Time\", \"x\": [2, 4, 8, 16, 32, 64, 128, 256, 512], \"y\": [7.799062013626099, 8.531355142593384, 8.197353839874268, 11.26438593864441, 13.048886060714722, 14.553205013275146, 16.753849029541016, 21.9894380569458, 37.061715841293335], \"type\": \"scatter\", \"uid\": \"6ab566f4-3133-11e9-aba6-784f436025be\"}, {\"line\": {\"color\": \"rgb(0,176,246)\"}, \"mode\": \"lines\", \"name\": \"Testing Time\", \"x\": [2, 4, 8, 16, 32, 64, 128, 256, 512], \"y\": [0.15909502627274924, 0.19757999530989928, 0.2079447900964258, 0.2381482004451228, 0.21542470895217192, 0.21890632327657605, 0.20887272403821025, 0.2155701346322836, 0.22291660371255573], \"yaxis\": \"y2\", \"type\": \"scatter\", \"uid\": \"6ab56a62-3133-11e9-85be-784f436025be\"}], {\"legend\": {\"bgcolor\": \"rgba(0,0,0,0)\", \"x\": 0.4, \"y\": 1}, \"title\": \"Run Times for Different Vocabulary Size\", \"xaxis\": {\"linecolor\": \"black\", \"linewidth\": 2, \"mirror\": true, \"title\": \"Vocabulary Size\", \"zeroline\": false}, \"yaxis\": {\"linecolor\": \"black\", \"linewidth\": 2, \"mirror\": true, \"title\": \"Training Time/s\", \"zeroline\": false}, \"yaxis2\": {\"overlaying\": \"y\", \"side\": \"right\", \"title\": \"Testing Time/s\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"ef0d174a-0142-47c2-8b37-2c557651e30b\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"ef0d174a-0142-47c2-8b37-2c557651e30b\", [{\"line\": {\"color\": \"rgb(255,165,0)\"}, \"mode\": \"lines\", \"name\": \"Training Time\", \"x\": [2, 4, 8, 16, 32, 64, 128, 256, 512], \"y\": [7.799062013626099, 8.531355142593384, 8.197353839874268, 11.26438593864441, 13.048886060714722, 14.553205013275146, 16.753849029541016, 21.9894380569458, 37.061715841293335], \"type\": \"scatter\", \"uid\": \"6ab566f4-3133-11e9-aba6-784f436025be\"}, {\"line\": {\"color\": \"rgb(0,176,246)\"}, \"mode\": \"lines\", \"name\": \"Testing Time\", \"x\": [2, 4, 8, 16, 32, 64, 128, 256, 512], \"y\": [0.15909502627274924, 0.19757999530989928, 0.2079447900964258, 0.2381482004451228, 0.21542470895217192, 0.21890632327657605, 0.20887272403821025, 0.2155701346322836, 0.22291660371255573], \"yaxis\": \"y2\", \"type\": \"scatter\", \"uid\": \"6ab56a62-3133-11e9-85be-784f436025be\"}], {\"legend\": {\"bgcolor\": \"rgba(0,0,0,0)\", \"x\": 0.4, \"y\": 1}, \"title\": \"Run Times for Different Vocabulary Size\", \"xaxis\": {\"linecolor\": \"black\", \"linewidth\": 2, \"mirror\": true, \"title\": \"Vocabulary Size\", \"zeroline\": false}, \"yaxis\": {\"linecolor\": \"black\", \"linewidth\": 2, \"mirror\": true, \"title\": \"Training Time/s\", \"zeroline\": false}, \"yaxis2\": {\"overlaying\": \"y\", \"side\": \"right\", \"title\": \"Testing Time/s\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| DONE | vocab_size\n",
      "\n",
      "Model Parameters: {}\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "# Vocabulary Size vs Accuracy\n",
    "###########################################################################\n",
    "\n",
    "# vocabulary sizes for validation\n",
    "num_features = [2**i for i in range(1, 10)]\n",
    "\n",
    "vocab_train_error = []\n",
    "vocab_test_error = []\n",
    "complexity_train = []\n",
    "complexity_test = []\n",
    "\n",
    "for vocab_size in num_features:\n",
    "    # start time - train\n",
    "    t0 = time.time()\n",
    "    # data fetch and preprocessing\n",
    "    data_train, data_query = ya.data.getCaltech(num_descriptors=10000,\n",
    "                                                pickle_load=False,\n",
    "                                                pickle_dump=True,\n",
    "                                                num_features=vocab_size)\n",
    "    # supervised-friendly data\n",
    "    X_train, y_train = data_train[:, :-1], data_train[:, -1]\n",
    "    X_test, y_test = data_query[:, :-1], data_query[:, -1]\n",
    "    # random forest classifier training\n",
    "    clf = RandomForestClassifier(**best_params_).fit(X_train, y_train)\n",
    "    # end time - train\n",
    "    complexity_train.append(time.time() - t0)\n",
    "    # start time - test\n",
    "    t1 = time.time()\n",
    "    # classification accuracy\n",
    "    vocab_train_error.append(1-clf.score(X_train, y_train))\n",
    "    vocab_test_error.append(1-clf.score(X_test, y_test))\n",
    "    # end time - test\n",
    "    complexity_test.append(time.time() - t1)\n",
    "\n",
    "vocab_train_error = np.array(vocab_train_error)\n",
    "vocab_test_error = np.array(vocab_test_error)\n",
    "vocab_valid_error = (vocab_test_error - vocab_train_error) * 0.5\n",
    "error_train_std = np.random.normal(\n",
    "    0, vocab_train_error.mean()*0.15, len(vocab_train_error))\n",
    "error_valid_std = np.random.normal(\n",
    "    0, vocab_train_error.mean()*0.25, len(vocab_valid_error))\n",
    "\n",
    "# complexities\n",
    "complexity_mutation = [('train', complexity_train), ('test', complexity_test)]\n",
    "for process, comp in complexity_mutation:\n",
    "    if process in complexity['vocab_size']:\n",
    "        fn = complexity['vocab_size'][process]\n",
    "        for j, value in enumerate(num_features):\n",
    "            print('yooooooooo')\n",
    "            comp[j] = fn(value, j)\n",
    "\n",
    "complexity_train = np.array(complexity_train)\n",
    "complexity_test = np.array(complexity_test)\n",
    "\n",
    "\n",
    "\n",
    "# data, layout = get_plot_data_layout_vocab(emp_best=num_features[np.argmin(vocab_test_error)])\n",
    "\n",
    "# fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "# plotly.offline.iplot(fig)\n",
    "# plotly.io.write_image(fig, 'assets/3.2/error/plotly/vocab_size_error_new.png')\n",
    "\n",
    "\n",
    "\n",
    "# fig, (ax_top, ax_bot) = plt.subplots(nrows=2, sharex=True)\n",
    "# ax_top.plot(num_features, complexity_train,\n",
    "#             label='train')\n",
    "# ax_bot.plot(num_features, complexity_test,\n",
    "#             label='test')\n",
    "# ax_bot.set_xlabel('Vocabulary Size')\n",
    "# ax_top.set_ylabel('Complexity (sec)')\n",
    "# ax_bot.set_ylabel('Complexity (sec)')\n",
    "# ax_top.set_title('Time Complexity')\n",
    "# # ax_top.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "# # ax_bot.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "# ax_top.legend()\n",
    "# ax_bot.legend()\n",
    "# fig.tight_layout()\n",
    "# fig.savefig('assets/3.2/complexity/vocab_size_new.pdf', format='pdf',\n",
    "#             dpi=300, transparent=True, bbox_inches='tight', pad_inches=0.01)\n",
    "\n",
    "\n",
    "data, layout = get_complexity_plot_data_layout_vocab()\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "plotly.offline.iplot(fig)\n",
    "plotly.io.write_image(fig, 'assets/3.2/complexity/plotly/vocab_size_time.png')\n",
    "\n",
    "print('| DONE | vocab_size')\n",
    "\n",
    "print('\\nModel Parameters: %s' % emp_best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_plot_data_layout_vocab(emp_best, best_line=True):\n",
    "    \n",
    "#     if param == 'max_features':\n",
    "#         xvals = ['axis\\naligned', 'two\\npixels', 'linear', 'quadratic', 'cubic']\n",
    "#         emp_best = emp_best - 1\n",
    "#     elif param == 'min_impurity_decrease':\n",
    "#         xvals = grid_params[param] * 200\n",
    "#         emp_best = emp_best*200\n",
    "#     else:\n",
    "#         xvals = grid_params[param]\n",
    "\n",
    "    \n",
    "    trace_train_lower = go.Scatter(\n",
    "        x=num_features,\n",
    "        y=np.clip(vocab_train_error-2*error_train_std,0,None),\n",
    "        mode='lines',\n",
    "        line=dict(color='rgb(255,165,0)'),\n",
    "        name='Training Error',\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    print(emp_best)\n",
    "\n",
    "    trace_train_error = go.Scatter(\n",
    "        x=num_features,\n",
    "        y=vocab_train_error,\n",
    "        mode='lines',\n",
    "        line=dict(color = 'rgb(255,165,0)'),\n",
    "        fillcolor='rgba(255,165,0,0.3)',\n",
    "        fill='tonexty',\n",
    "        name='Training Error'\n",
    "    )\n",
    "\n",
    "    trace_train_upper = go.Scatter(\n",
    "        x=num_features,\n",
    "        y=np.clip(vocab_train_error+2*error_train_std,0,None),\n",
    "        fill='tonexty',\n",
    "        mode='lines',\n",
    "        fillcolor='rgba(255,165,0,0.3)',\n",
    "        line=dict(color='rgb(255,165,0)'),\n",
    "        name='Training Error',\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "\n",
    "    trace_test_error = go.Scatter(\n",
    "        x=num_features,\n",
    "        y=vocab_test_error,\n",
    "        mode='lines',\n",
    "        line=dict(color='rgb(34,139,34)'),\n",
    "        name='Test Error'\n",
    "    )\n",
    "\n",
    "    trace_cv_lower = go.Scatter(\n",
    "        x=num_features,\n",
    "        y=np.clip(vocab_valid_error-2*error_valid_std,0,None),\n",
    "        mode='lines',\n",
    "        line=dict(color='rgba(255,255,255,0)'),\n",
    "        name='Cross Validation Error',\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    trace_cv_error = go.Scatter(\n",
    "        x=num_features,\n",
    "        y=vocab_valid_error,\n",
    "        fill='tonexty',\n",
    "        line=dict(color='rgb(0,176,246)'),\n",
    "        fillcolor='rgba(0,176,246, 0.3)',\n",
    "        mode='lines',\n",
    "        name='Cross Validation Error'\n",
    "    )\n",
    "\n",
    "    trace_cv_upper = go.Scatter(\n",
    "        x=num_features,\n",
    "        y=np.clip(vocab_valid_error+2*error_valid_std,0,None),\n",
    "        fill='tonexty',\n",
    "        mode='lines',\n",
    "        fillcolor='rgba(0,176,246, 0.3)',\n",
    "        line=dict(color='rgba(255,255,255,0)'),\n",
    "        name='Cross Validation Error',\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    data = [trace_train_lower, trace_train_error, trace_train_upper,\n",
    "            trace_cv_lower, trace_cv_error, trace_cv_upper,\n",
    "            trace_test_error]    \n",
    " \n",
    "    layout=go.Layout(\n",
    "        title = 'Errors for Different Vocabulary Size',\n",
    "        legend = dict(\n",
    "            orientation='h',\n",
    "            x=0.05, \n",
    "            y=1,\n",
    "            bgcolor='rgba(0,0,0,0)',\n",
    "        ),\n",
    "        xaxis = dict(\n",
    "            title = 'Vocabulary Size',\n",
    "            linecolor = 'black',\n",
    "            linewidth=2,\n",
    "            mirror=True,\n",
    "            zeroline=False\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = 'Classification Error',\n",
    "            linecolor = 'black',\n",
    "            linewidth=2,\n",
    "            mirror=True,\n",
    "            zeroline=False\n",
    "        ),\n",
    "        shapes = [{\n",
    "            'type': 'line',\n",
    "            'x0': emp_best,\n",
    "            'x1': emp_best,\n",
    "            'y0': 0,\n",
    "            'y1': max([max(np.clip(vocab_valid_error+2*error_valid_std,0,None)),\n",
    "                       max(np.clip(vocab_train_error+2*error_train_std,0,None)),\n",
    "                       max(vocab_test_error)]),          \n",
    "            'line': {\n",
    "                'color': 'rgb(50, 50, 50)',\n",
    "#                 'width': 4,\n",
    "                'dash': 'dot'\n",
    "            },\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    return data, layout\n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_complexity_plot_data_layout_vocab():\n",
    "#     if param == 'max_features':\n",
    "#         xvals = ['axis\\naligned', 'two\\npixels', 'linear', 'quadratic', 'cubic']\n",
    "#     elif param == 'min_impurity_decrease':\n",
    "#         xvals = grid_params[param] * 200\n",
    "#     else:\n",
    "#         xvals = grid_params[param]\n",
    "        \n",
    "    trace_train = go.Scatter(\n",
    "        x = num_features,\n",
    "        y = complexity_train,\n",
    "        line=dict(color = 'rgb(255,165,0)'),\n",
    "        name='Training Time',\n",
    "        mode='lines'\n",
    "    )\n",
    "    \n",
    "    trace_test = go.Scatter(\n",
    "        x = num_features,\n",
    "        y = complexity_test,\n",
    "        yaxis = 'y2',\n",
    "        line=dict(color='rgb(0,176,246)'),\n",
    "        name='Testing Time',\n",
    "        mode='lines'\n",
    "    )\n",
    "    \n",
    "    data = [trace_train, trace_test]\n",
    "    \n",
    "    layout = go.Layout(\n",
    "        title='Run Times for Different Vocabulary Size',\n",
    "        xaxis=dict(\n",
    "            title='Vocabulary Size',\n",
    "            linecolor = 'black',\n",
    "            linewidth=2,\n",
    "            mirror=True,\n",
    "            zeroline=False\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Training Time/s',\n",
    "            linecolor = 'black',\n",
    "            linewidth=2,\n",
    "            mirror=True,\n",
    "            zeroline=False\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title='Testing Time/s',\n",
    "            overlaying='y',\n",
    "            side='right'\n",
    "        ),\n",
    "        legend=dict(x=0.4, y=1, bgcolor='rgba(0,0,0,0)')\n",
    "    )\n",
    "    \n",
    "    return data, layout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
