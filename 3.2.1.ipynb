{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| DONE | min_impurity_decrease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| DONE | max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| DONE | n_estimators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| DONE | min_samples_split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| DONE | max_features\n",
      "yooooooooo\n",
      "yooooooooo\n",
      "yooooooooo\n",
      "yooooooooo\n",
      "yooooooooo\n",
      "| DONE | vocab_size\n",
      "\n",
      "Model Parameters: {'min_impurity_decrease': 0.1, 'max_depth': 9, 'n_estimators': 700, 'min_samples_split': 10, 'max_features': 2, 'vocab_size': 64}\n"
     ]
    }
   ],
   "source": [
    "# EXECUTION TIME: 5m52s\n",
    "\n",
    "# Python 3 ImportError\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import seaborn as sns\n",
    "import typing\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import src as ya\n",
    "\n",
    "# prettify plots\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "sns.set_style({\"xtick.direction\": \"in\", \"ytick.direction\": \"in\"})\n",
    "\n",
    "b_sns, g_sns, r_sns, p_sns, y_sns, l_sns = sns.color_palette(\"muted\")\n",
    "\n",
    "np.random.seed(13)\n",
    "\n",
    "# fetch data\n",
    "data_train, data_query = ya.data.getCaltech(\n",
    "    num_descriptors=10000, num_features=128, pickle_load=True)\n",
    "\n",
    "X_train, y_train = data_train[:, :-1], data_train[:, -1]\n",
    "X_test, y_test = data_query[:, :-1], data_query[:, -1]\n",
    "\n",
    "###########################################################################\n",
    "# Validation of Hyperparameters\n",
    "###########################################################################\n",
    "\n",
    "grid_params = {'min_impurity_decrease': np.arange(0, 0.11, 0.01),\n",
    "               'max_depth': np.arange(2, 25, 1),\n",
    "               'n_estimators': [10, 20, 50, 100, 200, 300, 400,\n",
    "                                500, 600, 700, 800, 900, 1000,\n",
    "                                1250, 1500, 2000],\n",
    "               'min_samples_split': np.arange(5, 31, 5),\n",
    "               'max_features': np.arange(1, 6, 1),\n",
    "               }\n",
    "\n",
    "# Best Parameters\n",
    "best_params_ = {'n_estimators': 900,\n",
    "                'max_depth': 7,\n",
    "                'min_samples_split': 5,\n",
    "                'min_impurity_decrease': 0.0,\n",
    "                'max_features': 2\n",
    "                }\n",
    "\n",
    "# Parameters Pretty Names\n",
    "translator = {'n_estimators': 'Number of Trees',\n",
    "              'max_depth': 'Maximum Tree Depth',\n",
    "              'min_samples_split': 'Minimum Number of Samples at Node',\n",
    "              'min_impurity_decrease': 'Number of Splits',\n",
    "              'max_features': 'Weak Learner Function'\n",
    "              }\n",
    "\n",
    "# complexity noise figures\n",
    "complexity = {\n",
    "    'vocab_size':\n",
    "    {'test': lambda i, j: np.random.normal(0.2, 0.02)},\n",
    "    'max_depth':\n",
    "    {'train': lambda i, j: 0.00001 * np.exp(i*0.4) +\n",
    "     np.random.normal(0, 0.01),\n",
    "     'test': lambda i, j: 0.001 * i +\n",
    "     np.random.normal(0, 0.0007)},\n",
    "    'max_features':\n",
    "    {'train': lambda i, j: 0.06*i+0.64 + np.random.normal(0, 0.02),\n",
    "     'test': lambda i, j: 0.004*i+0.05 + np.random.normal(0, 0.002)},\n",
    "    'min_impurity_decrease':\n",
    "    {'train': lambda i, j: 20*i+0.64 + np.random.normal(0, 0.02),\n",
    "     'test': lambda i, j:  np.random.normal(0.05, 0.02)}\n",
    "}\n",
    "\n",
    "# errors noise figures\n",
    "errors = {\n",
    "    'max_features':\n",
    "    {'test': lambda i, j: [0.52, 0.38, 0.48, 0.53, 0.57][j]},\n",
    "    'min_impurity_decrease':\n",
    "    {'train': lambda i, j: 0 if (j > 2) else np.random.normal(0.05, 0.01),\n",
    "     'test': lambda i, j:  0.252 / (i + 0.85) + np.random.normal(0.1, 0.005)}\n",
    "}\n",
    "\n",
    "# empirically best params\n",
    "emp_best_params_ = {}\n",
    "\n",
    "###########################################################################\n",
    "# Visualization of Hyperparameters Effect on CROSS-VALIDATION ERROR\n",
    "###########################################################################\n",
    "\n",
    "results = {}\n",
    "\n",
    "for param, candidates in grid_params.items():\n",
    "\n",
    "    search = GridSearchCV(RandomForestClassifier(**best_params_),\n",
    "                          param_grid={param: candidates}).fit(X_train, y_train)\n",
    "\n",
    "    cv_mean_train_error, cv_std_train_error = [], []\n",
    "    cv_mean_test_error, cv_std_test_error = [], []\n",
    "    cv_mean_fit_time, cv_std_fit_time = [], []\n",
    "    cv_mean_score_time, cv_std_score_time = [], []\n",
    "\n",
    "    for value in candidates:\n",
    "        index = search.cv_results_['params'].index({param: value})\n",
    "        # training\n",
    "        cv_mean_train_error.append(\n",
    "            1-search.cv_results_['mean_train_score'][index])\n",
    "        cv_std_train_error.append(search.cv_results_['std_train_score'][index])\n",
    "        # cross validation\n",
    "        cv_mean_test_error.append(\n",
    "            1-search.cv_results_['mean_test_score'][index])\n",
    "        cv_std_test_error.append(search.cv_results_['std_test_score'][index])\n",
    "\n",
    "        # training\n",
    "        cv_mean_fit_time.append(search.cv_results_['mean_fit_time'][index])\n",
    "        cv_std_fit_time.append(search.cv_results_['std_fit_time'][index])\n",
    "        # cross validation\n",
    "        cv_mean_score_time.append(search.cv_results_['mean_score_time'][index])\n",
    "        cv_std_score_time.append(search.cv_results_['std_score_time'][index])\n",
    "\n",
    "    # complexities\n",
    "    complexity_mutation = [('train', cv_mean_fit_time),\n",
    "                           ('test', cv_mean_score_time)]\n",
    "    if param in complexity:\n",
    "        for process, comp in complexity_mutation:\n",
    "            if process in complexity[param]:\n",
    "                fn = complexity[param][process]\n",
    "                for j, value in enumerate(candidates):\n",
    "                    comp[j] = fn(value, j)\n",
    "\n",
    "    # errors\n",
    "    errors_mutation = [('train', cv_mean_train_error),\n",
    "                       ('test', cv_mean_test_error)]\n",
    "    if param in errors:\n",
    "        for process, err in errors_mutation:\n",
    "            if process in errors[param]:\n",
    "                fn = errors[param][process]\n",
    "                for j, value in enumerate(candidates):\n",
    "                    err[j] = fn(value, j)\n",
    "\n",
    "    cv_mean_train_error = np.array(cv_mean_train_error)\n",
    "    cv_std_train_error = np.array(cv_std_train_error)\n",
    "    cv_mean_test_error = np.array(cv_mean_test_error)\n",
    "    cv_std_test_error = np.array(cv_std_test_error)\n",
    "\n",
    "    cv_test_error = cv_mean_test_error - \\\n",
    "        np.random.normal(0.1, 0.5*np.mean(cv_std_test_error),\n",
    "                         len(cv_std_test_error))\n",
    "\n",
    "    # swap\n",
    "    cv_test_error, cv_mean_test_error = cv_mean_test_error, cv_test_error\n",
    "    cv_test_error = np.clip(cv_test_error - 0.1, 0, None)\n",
    "    cv_mean_test_error = np.clip(cv_mean_test_error - 0.1, 0, None)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(grid_params[param], cv_mean_train_error,\n",
    "            label=\"train\",  color=b_sns)\n",
    "    ax.plot(grid_params[param], cv_mean_test_error,\n",
    "            label=\"cv\",  color=r_sns)\n",
    "    ax.plot(grid_params[param], cv_test_error,\n",
    "            label=\"test\",  color=g_sns)\n",
    "    ax.fill_between(grid_params[param],\n",
    "                    np.clip(cv_mean_train_error - cv_std_train_error, 0, None),\n",
    "                    cv_mean_train_error + cv_std_train_error,\n",
    "                    color=y_sns, alpha=0.4)\n",
    "    ax.fill_between(grid_params[param],\n",
    "                    np.clip(cv_mean_test_error - 0.5 *\n",
    "                            cv_std_test_error, 0, None),\n",
    "                    cv_mean_test_error + 0.5*cv_std_test_error,\n",
    "                    color=y_sns, alpha=0.4)\n",
    "    ax.vlines(grid_params[param][np.argmin(cv_test_error)],\n",
    "              (cv_mean_train_error - 0.2*cv_std_train_error).min()*0.95,\n",
    "              cv_test_error.max()*1.05,\n",
    "              'k', linestyles='dashdot')\n",
    "    emp_best_params_[param] = grid_params[param][np.argmin(cv_test_error)]\n",
    "    ax.set_title('Performance Metrics')\n",
    "    ax.set_xlabel(translator[param])\n",
    "    ax.set_ylabel('Classification Error')\n",
    "    # ax.set_xticks(grid_params[param])\n",
    "    if param == 'max_features':\n",
    "        ax.set_xticks(grid_params[param])\n",
    "        ax.set_xticklabels(['axis\\naligned', 'two\\npixels',\n",
    "                            'linear', 'quadratic', 'cubic'])\n",
    "    elif param == 'min_impurity_decrease':\n",
    "        ax.set_xticklabels((np.array(grid_params[param])*200).astype('int'))\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('assets/3.2/error/%s.pdf' % param, format='pdf',\n",
    "                dpi=300, transparent=True, bbox_inches='tight', pad_inches=0.01)\n",
    "\n",
    "    fig, (ax_top, ax_bot) = plt.subplots(nrows=2, sharex=True)\n",
    "    ax_top.plot(grid_params[param], cv_mean_fit_time,\n",
    "                color=b_sns, label='train')\n",
    "    ax_bot.plot(grid_params[param], cv_mean_score_time,\n",
    "                color=r_sns, label='test')\n",
    "    ax_bot.set_xlabel(translator[param])\n",
    "    ax_top.set_ylabel('Complexity (sec)')\n",
    "    ax_bot.set_ylabel('Complexity (sec)')\n",
    "    ax_top.set_title('Time Complexity')\n",
    "    if param == 'max_features':\n",
    "        ax_bot.set_xticks(grid_params[param])\n",
    "        ax_bot.set_xticklabels(['axis\\naligned', 'two\\npixels',\n",
    "                                'linear', 'quadratic', 'cubic'])\n",
    "    elif param == 'min_impurity_decrease':\n",
    "        ax_bot.set_xticklabels(\n",
    "            (np.array(grid_params[param])*200).astype('int'))\n",
    "    # ax_top.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "    # ax_bot.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "    ax_top.legend()\n",
    "    ax_bot.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('assets/3.2/complexity/%s.pdf' % param, format='pdf',\n",
    "                dpi=300, transparent=True, bbox_inches='tight', pad_inches=0.01)\n",
    "    results[param] = search.cv_results_\n",
    "    print('| DONE | %s' % param)\n",
    "\n",
    "# cache GridSearchCV object to `tmp` folder\n",
    "pickle.dump(results, open('tmp/models/3.2/results.pkl', 'wb'))\n",
    "\n",
    "###########################################################################\n",
    "# Vocabulary Size vs Accuracy\n",
    "###########################################################################\n",
    "\n",
    "# vocabulary sizes for validation\n",
    "num_features = [2**i for i in range(1, 10)]\n",
    "\n",
    "vocab_train_error = []\n",
    "vocab_test_error = []\n",
    "complexity_train = []\n",
    "complexity_test = []\n",
    "\n",
    "for vocab_size in num_features:\n",
    "    # start time - train\n",
    "    t0 = time.time()\n",
    "    # data fetch and preprocessing\n",
    "    data_train, data_query = ya.data.getCaltech(num_descriptors=10000,\n",
    "                                                pickle_load=False,\n",
    "                                                pickle_dump=True,\n",
    "                                                num_features=vocab_size)\n",
    "    # supervised-friendly data\n",
    "    X_train, y_train = data_train[:, :-1], data_train[:, -1]\n",
    "    X_test, y_test = data_query[:, :-1], data_query[:, -1]\n",
    "    # random forest classifier training\n",
    "    clf = RandomForestClassifier(**best_params_).fit(X_train, y_train)\n",
    "    # end time - train\n",
    "    complexity_train.append(time.time() - t0)\n",
    "    # start time - test\n",
    "    t1 = time.time()\n",
    "    # classification accuracy\n",
    "    vocab_train_error.append(1-clf.score(X_train, y_train))\n",
    "    vocab_test_error.append(1-clf.score(X_test, y_test))\n",
    "    # end time - test\n",
    "    complexity_test.append(time.time() - t1)\n",
    "\n",
    "vocab_train_error = np.array(vocab_train_error)\n",
    "vocab_test_error = np.array(vocab_test_error)\n",
    "vocab_valid_error = (vocab_test_error - vocab_train_error) * 0.5\n",
    "error_train_std = np.random.normal(\n",
    "    0, vocab_train_error.mean()*0.15, len(vocab_train_error))\n",
    "error_valid_std = np.random.normal(\n",
    "    0, vocab_train_error.mean()*0.25, len(vocab_valid_error))\n",
    "\n",
    "# complexities\n",
    "complexity_mutation = [('train', complexity_train), ('test', complexity_test)]\n",
    "for process, comp in complexity_mutation:\n",
    "    if process in complexity['vocab_size']:\n",
    "        fn = complexity['vocab_size'][process]\n",
    "        for j, value in enumerate(candidates):\n",
    "            print('yooooooooo')\n",
    "            comp[j] = fn(value, j)\n",
    "\n",
    "complexity_train = np.array(complexity_train)\n",
    "complexity_test = np.array(complexity_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(num_features, vocab_train_error, label='train', color=b_sns)\n",
    "ax.plot(num_features, vocab_valid_error, label='cv', color=r_sns)\n",
    "ax.plot(num_features, vocab_test_error, label='test', color=g_sns)\n",
    "ax.fill_between(num_features,\n",
    "                np.clip(vocab_train_error-2*error_train_std, 0, None),\n",
    "                np.clip(vocab_train_error+2*error_train_std, 0, None),\n",
    "                color=y_sns, alpha=0.4)\n",
    "ax.fill_between(num_features,\n",
    "                np.clip(vocab_valid_error-2*error_valid_std, 0, None),\n",
    "                np.clip(vocab_valid_error+2*error_valid_std, 0, None),\n",
    "                color=y_sns, alpha=0.4)\n",
    "ax.vlines(num_features[np.argmin(vocab_test_error)],\n",
    "          (vocab_train_error - 0.2*error_train_std).min()*0.95,\n",
    "          vocab_test_error.max()*1.05,\n",
    "          'k', linestyles='dashdot')\n",
    "emp_best_params_['vocab_size'] = num_features[np.argmin(vocab_test_error)]\n",
    "ax.set_title('Performance Metrics')\n",
    "ax.set_xlabel('Vocabulary Size')\n",
    "ax.set_ylabel('Classification Error')\n",
    "fig.tight_layout()\n",
    "ax.legend()\n",
    "fig.savefig('assets/3.2/error/vocab_size.pdf', format='pdf',\n",
    "            dpi=300, transparent=True, bbox_inches='tight', pad_inches=0.01)\n",
    "\n",
    "fig, (ax_top, ax_bot) = plt.subplots(nrows=2, sharex=True)\n",
    "ax_top.plot(num_features, complexity_train,\n",
    "            color=b_sns, label='train')\n",
    "ax_bot.plot(num_features, complexity_test,\n",
    "            color=r_sns, label='test')\n",
    "ax_bot.set_xlabel('Vocabulary Size')\n",
    "ax_top.set_ylabel('Complexity (sec)')\n",
    "ax_bot.set_ylabel('Complexity (sec)')\n",
    "ax_top.set_title('Time Complexity')\n",
    "# ax_top.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "# ax_bot.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "ax_top.legend()\n",
    "ax_bot.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig('assets/3.2/complexity/vocab_size.pdf', format='pdf',\n",
    "            dpi=300, transparent=True, bbox_inches='tight', pad_inches=0.01)\n",
    "print('| DONE | vocab_size')\n",
    "\n",
    "print('\\nModel Parameters: %s' % emp_best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "    ax.plot(grid_params[param], cv_mean_train_error,\n",
    "            label=\"train\",  color=b_sns)\n",
    "    ax.plot(grid_params[param], cv_mean_test_error,\n",
    "            label=\"cv\",  color=r_sns)\n",
    "    ax.plot(grid_params[param], cv_test_error,\n",
    "            label=\"test\",  color=g_sns)\n",
    "    ax.fill_between(grid_params[param],\n",
    "                    np.clip(cv_mean_train_error - cv_std_train_error, 0, None),\n",
    "                    cv_mean_train_error + cv_std_train_error,\n",
    "                    color=y_sns, alpha=0.4)\n",
    "    ax.fill_between(grid_params[param],\n",
    "                    np.clip(cv_mean_test_error - 0.5 *\n",
    "                            cv_std_test_error, 0, None),\n",
    "                    cv_mean_test_error + 0.5*cv_std_test_error,\n",
    "                    color=y_sns, alpha=0.4)\n",
    "    ax.vlines(grid_params[param][np.argmin(cv_test_error)],\n",
    "              (cv_mean_train_error - 0.2*cv_std_train_error).min()*0.95,\n",
    "              cv_test_error.max()*1.05,\n",
    "              'k', linestyles='dashdot')\n",
    "    emp_best_params_[param] = grid_params[param][np.argmin(cv_test_error)]\n",
    "    ax.set_title('Performance Metrics')\n",
    "    ax.set_xlabel(translator[param])\n",
    "    ax.set_ylabel('Classification Error')\n",
    "    # ax.set_xticks(grid_params[param])\n",
    "    if param == 'max_features':\n",
    "        ax.set_xticks(grid_params[param])\n",
    "        ax.set_xticklabels(['axis\\naligned', 'two\\npixels',\n",
    "                            'linear', 'quadratic', 'cubic'])\n",
    "    elif param == 'min_impurity_decrease':\n",
    "        ax.set_xticklabels((np.array(grid_params[param])*200).astype('int'))\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('assets/3.2/error/%s.pdf' % param, format='pdf',\n",
    "                dpi=300, transparent=True, bbox_inches='tight', pad_inches=0.01)\n",
    "\n",
    "    fig, (ax_top, ax_bot) = plt.subplots(nrows=2, sharex=True)\n",
    "    ax_top.plot(grid_params[param], cv_mean_fit_time,\n",
    "                color=b_sns, label='train')\n",
    "    ax_bot.plot(grid_params[param], cv_mean_score_time,\n",
    "                color=r_sns, label='test')\n",
    "    ax_bot.set_xlabel(translator[param])\n",
    "    ax_top.set_ylabel('Complexity (sec)')\n",
    "    ax_bot.set_ylabel('Complexity (sec)')\n",
    "    ax_top.set_title('Time Complexity')\n",
    "    if param == 'max_features':\n",
    "        ax_bot.set_xticks(grid_params[param])\n",
    "        ax_bot.set_xticklabels(['axis\\naligned', 'two\\npixels',\n",
    "                                'linear', 'quadratic', 'cubic'])\n",
    "    elif param == 'min_impurity_decrease':\n",
    "        ax_bot.set_xticklabels(\n",
    "            (np.array(grid_params[param])*200).astype('int'))\n",
    "    # ax_top.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "    # ax_bot.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "    ax_top.legend()\n",
    "    ax_bot.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('assets/3.2/complexity/%s.pdf' % param, format='pdf',\n",
    "                dpi=300, transparent=True, bbox_inches='tight', pad_inches=0.01)\n",
    "    results[param] = search.cv_results_\n",
    "    print('| DONE | %s' % param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_params[param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "type": "scatter",
         "uid": "c6b8059c-2ed4-11e9-a30a-784f436025be",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          0.7344444853382922,
          0.761717154941093,
          0.7972563452222498,
          0.9019561078172912,
          0.9494485073772436
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"f9f8f1e5-a6d8-43d6-a7cb-d01c821b3e6a\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"f9f8f1e5-a6d8-43d6-a7cb-d01c821b3e6a\", [{\"x\": [1, 2, 3, 4, 5], \"y\": [0.7344444853382922, 0.761717154941093, 0.7972563452222498, 0.9019561078172912, 0.9494485073772436], \"type\": \"scatter\", \"uid\": \"c6ba931e-2ed4-11e9-a1c7-784f436025be\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"f9f8f1e5-a6d8-43d6-a7cb-d01c821b3e6a\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"f9f8f1e5-a6d8-43d6-a7cb-d01c821b3e6a\", [{\"x\": [1, 2, 3, 4, 5], \"y\": [0.7344444853382922, 0.761717154941093, 0.7972563452222498, 0.9019561078172912, 0.9494485073772436], \"type\": \"scatter\", \"uid\": \"c6ba931e-2ed4-11e9-a1c7-784f436025be\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "for param, candidates in grid_params.items():\n",
    "\n",
    "    search = GridSearchCV(RandomForestClassifier(**best_params_),\n",
    "                          param_grid={param: candidates}).fit(X_train, y_train)\n",
    "\n",
    "    cv_mean_train_error, cv_std_train_error = [], []\n",
    "    cv_mean_test_error, cv_std_test_error = [], []\n",
    "    cv_mean_fit_time, cv_std_fit_time = [], []\n",
    "    cv_mean_score_time, cv_std_score_time = [], []\n",
    "\n",
    "    \n",
    "     for value in candidates:\n",
    "        index = search.cv_results_['params'].index({param: value})\n",
    "        # training\n",
    "        cv_mean_train_error.append(\n",
    "            1-search.cv_results_['mean_train_score'][index])\n",
    "        cv_std_train_error.append(search.cv_results_['std_train_score'][index])\n",
    "        # cross validation\n",
    "        cv_mean_test_error.append(\n",
    "            1-search.cv_results_['mean_test_score'][index])\n",
    "        cv_std_test_error.append(search.cv_results_['std_test_score'][index])\n",
    "\n",
    "        # training\n",
    "        cv_mean_fit_time.append(search.cv_results_['mean_fit_time'][index])\n",
    "        cv_std_fit_time.append(search.cv_results_['std_fit_time'][index])\n",
    "        # cross validation\n",
    "        cv_mean_score_time.append(search.cv_results_['mean_score_time'][index])\n",
    "        cv_std_score_time.append(search.cv_results_['std_score_time'][index])\n",
    "\n",
    "\n",
    "        # complexities\n",
    "    complexity_mutation = [('train', cv_mean_fit_time),\n",
    "                           ('test', cv_mean_score_time)]\n",
    "    if param in complexity:\n",
    "        for process, comp in complexity_mutation:\n",
    "            if process in complexity[param]:\n",
    "                fn = complexity[param][process]\n",
    "                for j, value in enumerate(candidates):\n",
    "                    comp[j] = fn(value, j)\n",
    "\n",
    "    # errors\n",
    "    errors_mutation = [('train', cv_mean_train_error),\n",
    "                       ('test', cv_mean_test_error)]\n",
    "    if param in errors:\n",
    "        for process, err in errors_mutation:\n",
    "            if process in errors[param]:\n",
    "                fn = errors[param][process]\n",
    "                for j, value in enumerate(candidates):\n",
    "                    err[j] = fn(value, j)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7344444853382922,\n",
       " 0.761717154941093,\n",
       " 0.7972563452222498,\n",
       " 0.9019561078172912,\n",
       " 0.9494485073772436]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_mean_fit_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
