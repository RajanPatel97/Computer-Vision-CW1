{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fbf500ed8618>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMiniBatchKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "\n",
    "def histc(labels, bins=None, return_bins=False):\n",
    "    \"\"\"MATLAB `histc` equivalent.\"\"\"\n",
    "    labels = np.array(labels, dtype=int)\n",
    "    if bins is None:\n",
    "        bins = np.unique(labels)\n",
    "    bins = np.array(bins, dtype=int)\n",
    "    bincount = np.bincount(labels)\n",
    "    if len(bins) + 1 != len(bincount):\n",
    "        bincount = np.append(\n",
    "            bincount, [0 for _ in range(len(bins) + 1 - len(bincount))])\n",
    "    if return_bins:\n",
    "        return bincount[bins], bins\n",
    "    else:\n",
    "        return bincount[bins]\n",
    "\n",
    "\n",
    "def KMeans_Codebook(num_features, num_descriptors):\n",
    "    # root folder with images\n",
    "    folder_name = 'Caltech_101/101_ObjectCategories'\n",
    "    # list of folders of images classes\n",
    "    class_list = os.listdir(folder_name)\n",
    "    # macOS: discart '.DS_Store' file\n",
    "    if '.DS_Store' in class_list:\n",
    "        class_list.remove('.DS_Store')\n",
    "\n",
    "    # SIFT feature extractor\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    # TRAINING\n",
    "    # list of descriptors\n",
    "    descriptors_train = []\n",
    "    raw_train = defaultdict(dict)\n",
    "    # iterate over image classes\n",
    "    for c in range(len(class_list)):\n",
    "        # subfolder pointer\n",
    "        sub_folder_name = os.path.join(folder_name, class_list[c])\n",
    "        # filter non-images files out\n",
    "        img_list = glob.glob(os.path.join(sub_folder_name, '*.jpg'))\n",
    "        # shuffle images to break correlation\n",
    "        np.random.shuffle(img_list)\n",
    "        # training examples\n",
    "        img_train = img_list[:15]\n",
    "        # iterate over image samples of a class\n",
    "        for i in range(len(img_train)):\n",
    "            # fetch image sample\n",
    "            raw_img = cv2.imread(img_train[i])\n",
    "            img = raw_img.copy()\n",
    "            # convert to gray scale for SIFT compatibility\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            # apply SIFT algorithm\n",
    "            kp, des = sift.detectAndCompute(gray, None)\n",
    "            # store descriptors\n",
    "            raw_train[c][i] = des\n",
    "            for d in des:\n",
    "                descriptors_train.append(d)\n",
    "    # NumPy-friendly array of descriptors\n",
    "    descriptors_train = np.asarray(descriptors_train)\n",
    "    # random selection of descriptors WITHOUT REPLACEMENT\n",
    "    descriptors_random = descriptors_train[np.random.choice(\n",
    "        len(descriptors_train), min(len(descriptors_train),\n",
    "                                    num_descriptors),\n",
    "        replace=False)]\n",
    "\n",
    "    # TESTING\n",
    "    raw_test = defaultdict(dict)\n",
    "    # iterate over image classes\n",
    "    for c in range(len(class_list)):\n",
    "        # subfolder pointer\n",
    "        sub_folder_name = os.path.join(folder_name, class_list[c])\n",
    "        # filter non-images files out\n",
    "        img_list = glob.glob(os.path.join(sub_folder_name, '*.jpg'))\n",
    "        # testing examples\n",
    "        img_test = img_list[15:30]\n",
    "        # iterate over image samples of a class\n",
    "        for i in range(len(img_test)):\n",
    "            # fetch image sample\n",
    "            raw_img = cv2.imread(img_test[i])\n",
    "            img = raw_img.copy()\n",
    "            # convert to gray scale for SIFT compatibility\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            # apply SIFT algorithm\n",
    "            kp, des = sift.detectAndCompute(gray, None)\n",
    "            # store descriptors\n",
    "            raw_test[c][i] = des\n",
    "\n",
    "    codebook_algorithm = MiniBatchKMeans(n_clusters=num_features,\n",
    "                                         init='k-means++',\n",
    "                                         batch_size=num_descriptors//100\n",
    "                                         ).fit(descriptors_random)\n",
    "\n",
    "    # vector quantisation\n",
    "    data_train = np.zeros(\n",
    "        (len(class_list)*15, num_features+1))\n",
    "\n",
    "    for i in range(len(class_list)):\n",
    "        for j in range(15):\n",
    "            # determine centers distribution\n",
    "            idx = codebook_algorithm.predict(raw_train[i][j])\n",
    "            # set features\n",
    "            data_train[15 *\n",
    "                       (i)+j, :-1] = histc(idx,\n",
    "                                           range(num_features)) / len(idx)\n",
    "            # set label\n",
    "            data_train[15*(i)+j, -1] = i\n",
    "\n",
    "    # vector quantisation\n",
    "    data_query = np.zeros(\n",
    "        (len(class_list)*15, num_features+1))\n",
    "\n",
    "    for i in range(len(class_list)):\n",
    "        for j in range(15):\n",
    "            # determine centers distribution\n",
    "            idx = codebook_algorithm.predict(raw_test[i][j])\n",
    "            # set features\n",
    "            data_query[15 *\n",
    "                       (i)+j, :-1] = histc(idx,\n",
    "                                           range(num_features)) / len(idx)\n",
    "            # set label\n",
    "            data_query[15*(i)+j, -1] = i\n",
    "\n",
    "    return data_train, data_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-244b67e32a64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mticker\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMaxNLocator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msrc\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mya\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstruct\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mForestParams\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "# EXECUTION TIME: 28s\n",
    "\n",
    "# Python 3 ImportError\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import src as ya\n",
    "from src.struct import ForestParams\n",
    "\n",
    "# prettify plots\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "sns.set_style({\"xtick.direction\": \"in\", \"ytick.direction\": \"in\"})\n",
    "\n",
    "b_sns, g_sns, r_sns, p_sns, y_sns, l_sns = sns.color_palette(\"muted\")\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "###########################################################################\n",
    "# Visualize Raw & SIFT Training/Testing Samples from Caltech_101\n",
    "###########################################################################\n",
    "\n",
    "# set all hyperparameters to small values to speed codebook generation\n",
    "# since only interested in images generated at folder `assets/3.1/examples`\n",
    "data_train, data_query = ya.data.getCaltech(savefig_images=True,\n",
    "                                            num_descriptors=2,\n",
    "                                            pickle_load=False,\n",
    "                                            pickle_dump=False,\n",
    "                                            num_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
