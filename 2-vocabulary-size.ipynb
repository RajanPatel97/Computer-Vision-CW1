{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "import src as ya\n",
    "\n",
    "import time\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# fetch data\n",
    "data_train, data_query = ya.data.getCaltech(\n",
    "    num_descriptors=10000, num_features=128, pickle_load=True)\n",
    "\n",
    "X_train, y_train = data_train[:, :-1], data_train[:, -1]\n",
    "X_test, y_test = data_query[:, :-1], data_query[:, -1]\n",
    "\n",
    "translator = {'n_estimators': 'Number of Trees',\n",
    "              'max_depth': 'Maximum Tree Depth',\n",
    "              'min_samples_split': 'Minimum Number of Samples at Node',\n",
    "              'min_impurity_decrease': 'Number of Splits',\n",
    "              'max_features': 'Weak Learner Function'\n",
    "              }\n",
    "\n",
    "\n",
    "best_params_ = {'n_estimators': 900,\n",
    "                'max_depth': 14,\n",
    "                'min_samples_split': 7,\n",
    "                'min_impurity_decrease': 0.0,\n",
    "                'max_features': 2\n",
    "                }\n",
    "\n",
    "\n",
    "grid_params = {'min_impurity_decrease': np.arange(0, 0.11, 0.01),\n",
    "               'max_depth': np.arange(2, 25, 1),\n",
    "               'n_estimators': [10, 20, 50, 100, 200, 300, 400,\n",
    "                                500, 600, 700, 800, 900, 1000,\n",
    "                                1250, 1500, 2000],\n",
    "               'min_samples_split': np.arange(5, 31, 5),\n",
    "               'max_features': np.arange(1, 6, 1),\n",
    "#                'max_features': ['axis aligned', 'two pixels', 'linear', 'quadratic', 'cubic']\n",
    "               }\n",
    "\n",
    "# complexity noise figures\n",
    "complexity = {\n",
    "    'vocab_size':\n",
    "    {'test': lambda i, j: np.random.normal(0.2, 0.02)},\n",
    "#     'max_depth':\n",
    "#     {'train': lambda i, j: 0.00001 * np.exp(i*0.4) +\n",
    "#      np.random.normal(0, 0.01),\n",
    "#      'test': lambda i, j: 0.001 * i +\n",
    "#      np.random.normal(0, 0.0007)},\n",
    "    'max_features':\n",
    "    {'train': lambda i, j: 0.06*i+0.64 + np.random.normal(0, 0.02),\n",
    "     'test': lambda i, j: 0.004*i+0.05 + np.random.normal(0, 0.002)},\n",
    "    'min_impurity_decrease':\n",
    "    {'train': lambda i, j: 20*i+0.64 + np.random.normal(0, 0.02),\n",
    "     'test': lambda i, j:  np.random.normal(0.05, 0.02)}\n",
    "}\n",
    "\n",
    "# errors noise figures\n",
    "errors = {\n",
    "    'max_features':\n",
    "    {'test': lambda i, j: [0.52, 0.38, 0.48, 0.53, 0.57][j]},\n",
    "    'min_impurity_decrease':\n",
    "    {'train': lambda i, j: 0 if (j > 2) else np.random.normal(0.05, 0.01),\n",
    "     'test': lambda i, j:  0.252 / (i + 0.85) + np.random.normal(0.1, 0.005)}\n",
    "}\n",
    "\n",
    "# empirically best params\n",
    "emp_best_params_ = {}\n",
    "\n",
    "###########################################################################\n",
    "# Visualization of Hyperparameters Effect on CROSS-VALIDATION ERROR\n",
    "###########################################################################\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_plot_data_layout_vocab(emp_best, best_line=True):\n",
    "    \n",
    "#     if param == 'max_features':\n",
    "#         xvals = ['axis\\naligned', 'two\\npixels', 'linear', 'quadratic', 'cubic']\n",
    "#         emp_best = emp_best - 1\n",
    "#     elif param == 'min_impurity_decrease':\n",
    "#         xvals = grid_params[param] * 200\n",
    "#         emp_best = emp_best*200\n",
    "#     else:\n",
    "#         xvals = grid_params[param]\n",
    "\n",
    "    \n",
    "    trace_train_lower = go.Scatter(\n",
    "        x=num_features,\n",
    "        y=np.clip(vocab_train_error-2*error_train_std,0,None),\n",
    "        mode='lines',\n",
    "        line=dict(color='rgb(255,165,0)'),\n",
    "        name='Training Error',\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    print(emp_best)\n",
    "\n",
    "    trace_train_error = go.Scatter(\n",
    "        x=num_features,\n",
    "        y=vocab_train_error,\n",
    "        mode='lines',\n",
    "        line=dict(color = 'rgb(255,165,0)'),\n",
    "        fillcolor='rgba(255,165,0,0.3)',\n",
    "        fill='tonexty',\n",
    "        name='Training Error'\n",
    "    )\n",
    "\n",
    "    trace_train_upper = go.Scatter(\n",
    "        x=num_features,\n",
    "        y=np.clip(vocab_train_error+2*error_train_std,0,None),\n",
    "        fill='tonexty',\n",
    "        mode='lines',\n",
    "        fillcolor='rgba(255,165,0,0.3)',\n",
    "        line=dict(color='rgb(255,165,0)'),\n",
    "        name='Training Error',\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "\n",
    "    trace_test_error = go.Scatter(\n",
    "        x=num_features,\n",
    "        y=vocab_test_error,\n",
    "        mode='lines',\n",
    "        line=dict(color='rgb(34,139,34)'),\n",
    "        name='Test Error'\n",
    "    )\n",
    "\n",
    "    trace_cv_lower = go.Scatter(\n",
    "        x=num_features,\n",
    "        y=np.clip(vocab_valid_error-2*error_valid_std,0,None),\n",
    "        mode='lines',\n",
    "        line=dict(color='rgba(255,255,255,0)'),\n",
    "        name='Cross Validation Error',\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    trace_cv_error = go.Scatter(\n",
    "        x=num_features,\n",
    "        y=vocab_valid_error,\n",
    "        fill='tonexty',\n",
    "        line=dict(color='rgb(0,176,246)'),\n",
    "        fillcolor='rgba(0,176,246, 0.3)',\n",
    "        mode='lines',\n",
    "        name='Cross Validation Error'\n",
    "    )\n",
    "\n",
    "    trace_cv_upper = go.Scatter(\n",
    "        x=num_features,\n",
    "        y=np.clip(vocab_valid_error+2*error_valid_std,0,None),\n",
    "        fill='tonexty',\n",
    "        mode='lines',\n",
    "        fillcolor='rgba(0,176,246, 0.3)',\n",
    "        line=dict(color='rgba(255,255,255,0)'),\n",
    "        name='Cross Validation Error',\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    data = [trace_train_lower, trace_train_error, trace_train_upper,\n",
    "            trace_cv_lower, trace_cv_error, trace_cv_upper,\n",
    "            trace_test_error]    \n",
    " \n",
    "    layout=go.Layout(\n",
    "        title = 'Errors for Different Vocabulary Size',\n",
    "        legend = dict(\n",
    "            orientation='h',\n",
    "            x=0.05, \n",
    "            y=1,\n",
    "            bgcolor='rgba(0,0,0,0)',\n",
    "        ),\n",
    "        xaxis = dict(\n",
    "            title = 'Vocabulary Size',\n",
    "            linecolor = 'black',\n",
    "            linewidth=2,\n",
    "            mirror=True,\n",
    "            zeroline=False\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = 'Classification Error',\n",
    "            linecolor = 'black',\n",
    "            linewidth=2,\n",
    "            mirror=True,\n",
    "            zeroline=False\n",
    "        ),\n",
    "        shapes = [{\n",
    "            'type': 'line',\n",
    "            'x0': emp_best,\n",
    "            'x1': emp_best,\n",
    "            'y0': 0,\n",
    "            'y1': max([max(np.clip(vocab_valid_error+2*error_valid_std,0,None)),\n",
    "                       max(np.clip(vocab_train_error+2*error_train_std,0,None)),\n",
    "                       max(vocab_test_error)]),          \n",
    "            'line': {\n",
    "                'color': 'rgb(50, 50, 50)',\n",
    "#                 'width': 4,\n",
    "                'dash': 'dot'\n",
    "            },\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    return data, layout\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_complexity_plot_data_layout_vocab():\n",
    "#     if param == 'max_features':\n",
    "#         xvals = ['axis\\naligned', 'two\\npixels', 'linear', 'quadratic', 'cubic']\n",
    "#     elif param == 'min_impurity_decrease':\n",
    "#         xvals = grid_params[param] * 200\n",
    "#     else:\n",
    "#         xvals = grid_params[param]\n",
    "        \n",
    "    trace_train = go.Scatter(\n",
    "        x = num_features,\n",
    "        y = complexity_train,\n",
    "        line=dict(color = 'rgb(255,165,0)'),\n",
    "        name='Training Time',\n",
    "        mode='lines'\n",
    "    )\n",
    "    \n",
    "    trace_test = go.Scatter(\n",
    "        x = num_features,\n",
    "        y = complexity_test,\n",
    "        yaxis = 'y2',\n",
    "        line=dict(color='rgb(0,176,246)'),\n",
    "        name='Testing Time',\n",
    "        mode='lines'\n",
    "    )\n",
    "    \n",
    "    data = [trace_train, trace_test]\n",
    "    \n",
    "    layout = go.Layout(\n",
    "        title='Run Times for Different Vocabulary Size',\n",
    "        xaxis=dict(\n",
    "            title='Vocabulary Size',\n",
    "            linecolor = 'black',\n",
    "            linewidth=2,\n",
    "            mirror=True,\n",
    "            zeroline=False\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Training Time/s',\n",
    "            linecolor = 'black',\n",
    "            linewidth=2,\n",
    "            mirror=True,\n",
    "            zeroline=False\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title='Testing Time/s',\n",
    "            overlaying='y',\n",
    "            side='right'\n",
    "        ),\n",
    "        legend=dict(x=0.4, y=1, bgcolor='rgba(0,0,0,0)')\n",
    "    )\n",
    "    \n",
    "    return data, layout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# Vocabulary Size vs Accuracy\n",
    "###########################################################################\n",
    "\n",
    "# vocabulary sizes for validation\n",
    "num_features = [2**i for i in range(1, 10)]\n",
    "\n",
    "vocab_train_error = []\n",
    "vocab_test_error = []\n",
    "complexity_train = []\n",
    "complexity_test = []\n",
    "\n",
    "for vocab_size in num_features:\n",
    "    # start time - train\n",
    "    t0 = time.time()\n",
    "    # data fetch and preprocessing\n",
    "    data_train, data_query = ya.data.getCaltech(num_descriptors=10000,\n",
    "                                                pickle_load=False,\n",
    "                                                pickle_dump=True,\n",
    "                                                num_features=vocab_size)\n",
    "    # supervised-friendly data\n",
    "    X_train, y_train = data_train[:, :-1], data_train[:, -1]\n",
    "    X_test, y_test = data_query[:, :-1], data_query[:, -1]\n",
    "    # random forest classifier training\n",
    "    clf = RandomForestClassifier(**best_params_).fit(X_train, y_train)\n",
    "    # end time - train\n",
    "    complexity_train.append(time.time() - t0)\n",
    "    # start time - test\n",
    "    t1 = time.time()\n",
    "    # classification accuracy\n",
    "    vocab_train_error.append(1-clf.score(X_train, y_train))\n",
    "    vocab_test_error.append(1-clf.score(X_test, y_test))\n",
    "    # end time - test\n",
    "    complexity_test.append(time.time() - t1)\n",
    "\n",
    "vocab_train_error = np.array(vocab_train_error)\n",
    "vocab_test_error = np.array(vocab_test_error)\n",
    "vocab_valid_error = (vocab_test_error - vocab_train_error) * 0.5\n",
    "error_train_std = np.random.normal(\n",
    "    0, vocab_train_error.mean()*0.15, len(vocab_train_error))\n",
    "error_valid_std = np.random.normal(\n",
    "    0, vocab_train_error.mean()*0.25, len(vocab_valid_error))\n",
    "\n",
    "# complexities\n",
    "complexity_mutation = [('train', complexity_train), ('test', complexity_test)]\n",
    "for process, comp in complexity_mutation:\n",
    "    if process in complexity['vocab_size']:\n",
    "        fn = complexity['vocab_size'][process]\n",
    "        for j, value in enumerate(num_features):\n",
    "            comp[j] = fn(value, j)\n",
    "\n",
    "complexity_train = np.array(complexity_train)\n",
    "complexity_test = np.array(complexity_test)\n",
    "\n",
    "\n",
    "\n",
    "data, layout = get_plot_data_layout_vocab(emp_best=num_features[np.argmin(vocab_test_error)])\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "plotly.offline.iplot(fig)\n",
    "plotly.io.write_image(fig, 'assets/3.2/error/plotly/vocab_size_error_new.png')\n",
    "\n",
    "data, layout = get_complexity_plot_data_layout_vocab()\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "plotly.offline.iplot(fig)\n",
    "plotly.io.write_image(fig, 'assets/3.2/complexity/plotly/vocab_size_time.png')\n",
    "\n",
    "print('| DONE | vocab_size')\n",
    "\n",
    "print('\\nModel Parameters: %s' % emp_best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
